# Experiments

Running experiments for "transfer": walker-walk-backwards.

CUDA_VISIBLE_DEVICES=0 python -m scripts.tdmpc2.train \
    task=walker-walk-backwards \
    encoder_and_dynamics_freeze=true \
    'encoder_and_dynamics_checkpoint="/scratch/gsk6me/robotics-research/uva-learning-for-interactive-robotics-project/episodes/v05,task=walker-walk-invdyn,seed=2/models/step_200000.pt"' \
		seed=2 \
    'wandb_name="v05,task=walker-walk-backwards,from=walker-walk-invdyn-seed-2"'

CUDA_VISIBLE_DEVICES=1 python -m scripts.tdmpc2.train \
    task=walker-walk-backwards \
    encoder_and_dynamics_freeze=true \
    'encoder_and_dynamics_checkpoint="/scratch/gsk6me/robotics-research/uva-learning-for-interactive-robotics-project/episodes/v05,task=walker-walk-rewards,seed=2/models/step_200000.pt"' \
		seed=2 \
    'wandb_name="v05,task=walker-walk-backwards,from=walker-walk-rewards-seed-2"'


CUDA_VISIBLE_DEVICES=3 python -m scripts.tdmpc2.train \
    task=walker-walk-backwards \
    encoder_and_dynamics_freeze=false \
		seed=2 \
    action_inference_coef=0 \
    stopgrad_reward_and_q=false \
    'wandb_name="v05,task=walker-walk-backwards-rewards,seed=2"'

### This one is not running yet.
CUDA_VISIBLE_DEVICES=2 python -m scripts.tdmpc2.train \
    task=walker-walk-backwards \
    encoder_and_dynamics_freeze=false \
		seed=2 \
    'wandb_name="v05,task=walker-walk-backwards-invdyn,seed=2"'

### Trying this one instead. Self-supervised prediction!

The default parameters in config.yaml will result in the same behavior.

CUDA_VISIBLE_DEVICES=2 python -m scripts.tdmpc2.train task=walker-walk environment_reward_coef=0 prediction_error_reward_coef=100 'wandb_name="v06_walker-walk-intrinsic-reward,seed=1"'
