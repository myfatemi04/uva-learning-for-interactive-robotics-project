# Experiments

Wondering why the newer models are a lot worse. Comparing the loss curves, consistency loss isn't going down so much.

CUDA_VISIBLE_DEVICES=0 python -m scripts.tdmpc2.train \
    task=walker-walk \
    encoder_and_dynamics_freeze=false \
		seed=2 \
    'wandb_name="v05,task=walker-walk-invdyn,seed=2"'

CUDA_VISIBLE_DEVICES=1 python -m scripts.tdmpc2.train \
    task=walker-walk \
    encoder_and_dynamics_freeze=false \
		seed=3 \
    'wandb_name="v05,task=walker-walk-invdyn,seed=3"'

### this one was cancelled
CUDA_VISIBLE_DEVICES=2 python -m scripts.tdmpc2.train \
    task=walker-walk \
    encoder_and_dynamics_freeze=false \
		seed=4 \
    'wandb_name="v05,task=walker-walk-invdyn,seed=4"'

### ... and this one took its place
CUDA_VISIBLE_DEVICES=2 python -m scripts.tdmpc2.train \
    task=walker-walk \
    encoder_and_dynamics_freeze=false \
		seed=2 \
    action_inference_coef=0 \
    stopgrad_reward_and_q=false \
    'wandb_name="v05,task=walker-walk-rewards,seed=2"'
