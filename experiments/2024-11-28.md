# Michael

Going to register a walker-walk-backwards environment.

walker-walk (from scratch, again, inverse dynamics)
CUDA_VISIBLE_DEVICES=0 python -m scripts.tdmpc2.train \
    task=walker-walk \
    encoder_and_dynamics_freeze=false \
    'wandb_name="v05,task=walker-walk-invdyn"'

walker-walk-backwards (from scratch, trained with rewards)
CUDA_VISIBLE_DEVICES=1 python -m scripts.tdmpc2.train \
    task=walker-walk-backwards \
    encoder_and_dynamics_freeze=false \
    action_inference_coef=0 \
    stopgrad_reward_and_q=false \
    'wandb_name="v05,task=walker-walk-backwards-rewards"'

walker-walk-backwards (from reward-only model)
CUDA_VISIBLE_DEVICES=2 python -m scripts.tdmpc2.train \
    task=walker-walk-backwards \
    'encoder_and_dynamics_checkpoint="/scratch/gsk6me/robotics-research/uva-learning-for-interactive-robotics-project/episodes/v05,task=walker-walk,rewardonly/step_108000.pt"' \
    encoder_and_dynamics_freeze=true \
    'wandb_name="v05,task=walker-walk-backwards-rewards,from=rewardonly"'

walker-walk-backwards (from inverse dynamics model)
CUDA_VISIBLE_DEVICES=3 python -m scripts.tdmpc2.train \
    task=walker-walk-backwards \
    'encoder_and_dynamics_checkpoint="/scratch/gsk6me/robotics-research/uva-learning-for-interactive-robotics-project/episodes/v05,task=walker-walk-invdyn/models/step_108000.pt"' \
    encoder_and_dynamics_freeze=true \
    action_inference_coef=0 \
    stopgrad_reward_and_q=false \
    'wandb_name="v05,task=walker-walk-backwards-rewards,from=invdyn"'
